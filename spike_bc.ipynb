{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as np\n",
    "import missingno as ms\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafío\n",
    "1. Baja el archivo ​caudal_extra.csv. ​Puedes bajarlo de BigQuery (vean el código al final de este documento), o bien, desde Github (h​ ttps://github.com/SpikeLab-CL/desafio_spike_cuencas)​ .\n",
    "2. Analiza el dataset ​caudal_extra.csv. ¿Qué puedes decir de los datos, distribuciones, missing, u otros? ¿Hay algo que te llame la atención? ¿Por qué hay tantos valores missing? Pensar en la manera en que se elaboró el dataset, descrito más arriba. (Entregable: texto/imágenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('caudal_extra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ms.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname, serie in df.iteritems():\n",
    "    print('--------------------')\n",
    "    print(colname, \"NA's %\\n\") \n",
    "    print(serie.isnull().value_counts('%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Descripción:\n",
    "\n",
    "Se puede observar que las columnas 'precip_promedio' y 'temp_max_promedio' poseen datos de tipo NaN o datos perdidos, siendo 'temp_max_promedio' aquella variable con mayor cantidad de datos faltantes, siendo el 10%, mientras que 'precip_promedio' presenta aproximadamente un 2% de datos perdidos. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['fecha'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ms.matrix(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Plots de precipitación, temperatura y caudal\n",
    "a. Escribir una función que tome como input una estación y haga plot de los datos para\n",
    "una columna. Debiese tener estos argumentos:\n",
    "def time_plot_una_estacion(codigo_estacion, columna, fecha_min, fecha_max):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plots de precipitacion, temperatura y caudal\n",
    "grid = sns.FacetGrid(df_1, col= 'codigo_estacion', col_wrap = 4)\n",
    "grid = grid.map(sns.scatterplot, 'temp_max_promedio', 'caudal' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacion = df_1['codigo_estacion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "#los datos de la columna 'fecha' estaban definidos con otro tipo, se convierte a tipo datetime64\n",
    "df_1['fecha'] = pd.to_datetime(df_1['fecha'])\n",
    "df_1['fecha'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['fecha'] = df_1['fecha'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def time_plot_una_estacion(codigo_estacion, columna, fecha_min, fecha_max):\n",
    "#    codigo_estacion = df_1[codigo_estacion]\n",
    "#    #col = df_1[columna]\n",
    "#    \n",
    "#    f_min = (fecha_min)\n",
    "#    f_max = (fecha_max)\n",
    "#    grid = sns.FacetGrid(df_1, col= columna, col_wrap = 4,  xlim = [f_min, f_max] )\n",
    "#    grid = grid.map(sns.scatterplot, 'temp_max_promedio', 'caudal' )\n",
    "#    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_min = '2000-09-24'\n",
    "#f_max = '2018-02-11'\n",
    "#grid = sns.FacetGrid(df_1, col= 'codigo_estacion', col_wrap = 4,  xlim = [f_min, f_max] )\n",
    "#grid = grid.map(sns.scatterplot, 'temp_max_promedio', 'caudal' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_min = ('2017-09-24')\n",
    "#f_max = ('2018-02-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.line(df_1, x ='precip_promedio', y='caudal', color= 'codigo_estacion' )\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['caudal',  'precip_promedio',  'temp_max_promedio']\n",
    "columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1['codigo_cuenca'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo_estacion = df_1['codigo_estacion'].unique()\n",
    "codigo_estacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_plot_una_estacion(codigo_estacion, columna, fecha_min, fecha_max):\n",
    "    #codigo_estacion = \n",
    "    f_min = (fecha_min)\n",
    "    f_max = (fecha_max)\n",
    "    codigo = i\n",
    "    fig = px.scatter(df_1, x ='fecha', y=columna, color = codigo, range_x = [f_min, f_max])\n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in columnas:\n",
    "    time_plot_una_estacion(codigo_estacion='12284007', columna = i, fecha_min='2000-09-24',fecha_max= '2018-02-11')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora escribir una función que haga plots de varias columnas, para poder visualizar caudal, precipitación y temperatura al mismo tiempo. Como las series están en diferentes escalas, sugerimos normalizarlas antes de hacer el plot (por ejemplo, dividiendo por la primera observación de cada seria)\n",
    "def time_plot_estaciones_varias_columnas(codigo_estacion, columnas, fecha_min, fecha_max):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 =df_1.loc[:,['caudal',  'precip_promedio',  'temp_max_promedio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['fecha'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(df_2)\n",
    "scaler = scaler.transform(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= pd.DataFrame(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_plot_estaciones_varias_columnas(codigo_estacion, columna_1, columna_2, columna_3, fecha_min, fecha_max):\n",
    "    codigo_estacion = codigo_estacion\n",
    "    cols = [columna_1, columna_2, columna_3]\n",
    "    f_min = (fecha_min)\n",
    "    f_max = (fecha_max)\n",
    "    fig = px.scatter(df_1, x ='fecha', y=scaler, color= codigo_estacion, range_x = [f_min, f_max])\n",
    "    return fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_plot_estaciones_varias_columnas(codigo_estacion ='12284007', columna_1='caudal',\n",
    "                                     columna_2= 'precip_promedio', columna_3= 'temp_max_promedio',\n",
    "                                     fecha_min='2000-09-24',fecha_max= '2018-02-11')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
